<!doctype html>
<html lang="zh-CN">

<head>
        <link rel="canonical" href="https://hysteriawindows.github.io/news/article-23935.htm" />
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>PyTorch的自动求导机制详细解析，PyTorch的核心魔法</title>
        <meta name="description" content="点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”   作者：Vaibhav Kumar 编译：ronghuaiyang   导读 这篇文章详细解析了PyTorch的自动求导机制，让你了解Py" />
        <link rel="icon" href="/assets/website/img/hysteriawindows/favicon.ico" type="image/x-icon"/>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="/assets/website/css/hysteriawindows/bootstrap.css">
    <link rel="stylesheet" href="/assets/website/css/hysteriawindows/themify-icons.css">
    <link rel="stylesheet" href="__ADDON__/js/frontend/hysteriawindows/fontawesome/css/all.min.css">
    <link rel="stylesheet" href="__ADDON__/js/frontend/hysteriawindows/owl-carousel/owl.carousel.min.css">
    <link rel="stylesheet" href="__ADDON__/js/frontend/hysteriawindows/animate-css/animate.css">
    <!-- main css -->
    <link rel="stylesheet" href="/assets/website/css/hysteriawindows/style.css">
    <link rel="stylesheet" href="/assets/website/css/hysteriawindows/responsive.css">
    
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W3GH5FWSVJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W3GH5FWSVJ');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body data-page="detail">
        <!--================Header Menu Area =================-->
    <header class="header_area">
        <div class="main_menu">
            <nav class="navbar navbar-expand-lg navbar-light">
                <div class="container">
                    <!-- Brand and toggle get grouped for better mobile display -->
                                        <a class="navbar-brand logo_h" href="/">
                        <span>Hysteria Windows</span>
                    </a>
                                        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse offset" id="navbarSupportedContent">
                        <ul class="nav navbar-nav menu_nav ml-auto">
                                                        <li class="nav-item"><a class="nav-link" href="/">首页</a></li>
                                                        <li class="nav-item"><a class="nav-link" href="/free-nodes/">免费节点</a></li>
                                                        <li class="nav-item"><a class="nav-link" href="/paid-subscribe/">推荐机场</a></li>
                                                        <li class="nav-item"><a class="nav-link" href="/news/">新闻资讯</a></li>
                                                        <li class="nav-item"><a class="nav-link" href="#">关于</a></li>
                            <li class="nav-item"><a class="nav-link" href="#">联系</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </header>
    <!--================Header Menu Area =================-->
    <!--================Hero Banner Area Start =================-->
    <section class="hero-banner d-flex align-items-center">
        <div class="container text-center">
            <h1>PyTorch的自动求导机制详细解析，PyTorch的核心魔法</h1>
            <nav aria-label="breadcrumb" class="banner-breadcrumb">
                <ol class="breadcrumb">
                    <li class="breadcrumb-item"><a href="/">首页</a></li>
                    <li class="breadcrumb-item"><a href="/news/">新闻资讯</a></li>
                    <li class="breadcrumb-item active" aria-current="page">正文</li>
                </ol>
            </nav>
        </div>
    </section>
    <!--================Hero Banner Area End =================-->
    <!--================About  Area =================-->
    <section class="statics-area area-padding">
        <div class="container">
            <div class="row">
                <div class="col-md-9">
                                      				  				  				<div id="content_views" class="htmledit_views"> <div class="rich_media_content" id="js_content"> <p style="color:inherit;font-size:inherit;min-height:1em;letter-spacing:.544px;font-family:'微软雅黑';line-height:inherit;text-align:center;"><span style="font-size:14px;">点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”</span></p> <hr style="color:inherit;font-size:inherit;letter-spacing:.544px;font-family:'微软雅黑';line-height:inherit;border-right:none;border-bottom:none;border-left:none;border-top-style:dashed;border-top-color:rgb(165,165,165);"/> <blockquote style="letter-spacing:.544px;"> <p style="min-height:1em;letter-spacing:.544px;font-family:'微软雅黑';font-size:16px;"><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">作</span><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">者：</span><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">Vaibhav Kumar</span></p> <p style="min-height:1em;letter-spacing:.544px;text-indent:0em;font-family:'微软雅黑';font-size:16px;color:rgb(62,62,62);"><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">编译：ronghuaiyang</span></p> </blockquote> <p> <span style="color:inherit;font-size:14px;"><strong style="color:rgb(102,102,102);"><span style="border-color:rgb(252,180,43);color:rgb(255,255,255);text-align:center;letter-spacing:2px;line-height:1.75em;">导读</span></strong></span></p> <p style="min-height:1em;color:inherit;letter-spacing:1.5px;line-height:1.75em;text-indent:0em;">这篇文章详细解析了PyTorch的自动求导机制，让你了解PyTorch的核心魔法。</p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/74b184c9f16e43d1c194885948f2eaf6.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p><span style="font-size:14px;"></span></p> <p> <center></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/0d23465615adfed4405b360b7e0ce2f2.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p>  <span style="font-size:14px;"></span><br />  </center><br />  <center><br />   <span style="font-size:14px;">在这个过程中，它从不显式地构造整个雅可比矩阵。</span><br />   <span style="font-size:14px;">直接计算JVP通常更简单、更有效。</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">我们都同意，当涉及到大型神经网络时，我们都不擅长微积分。通过显式求解数学方程来计算这样大的复合函数的梯度是不现实的，特别是这些曲线存在于大量的维数中，是无法理解的。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">要处理14维空间中的超平面，想象一个三维空间，大声地对自己说“14”。每个人都这么做——Geoffrey Hinton</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这就是PyTorch的autograd发挥作用的地方。它抽象了复杂的数学，帮助我们“神奇地”计算高维曲线的梯度，只需要几行代码。这篇文章试图描述autograd的魔力。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">PyTorch基础</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在进一步讨论之前，我们需要了解一些基本的PyTorch概念。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">张量：简单地说，它只是PyTorch中的一个n维数组。张量支持一些额外的增强，这使它们独一无二：除了CPU，它们可以加载或GPU更快的计算。在设置<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.requires_grad = True</code>的时候，他们开始形成一个反向图，跟踪应用于他们的每个操作，使用所谓的动态计算图(DCG)计算梯度(后面会进一步解释)。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在早期版本的PyTorch中，使用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.autograd.Variable</code>类用于创建支持梯度计算和操作跟踪的张量，但截至PyTorch v0.4.0，Variable类已被禁用。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.Tensor</code>和<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.autograd.Variable</code>现在是同一个类。更准确地说， <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.Tensor</code>能够跟踪历史并表现得像旧的<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Variable</code>。</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">torch</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">numpy</span> <span class="cm-keyword" style="font-size:14px;">as</span> <span class="cm-variable" style="font-size:14px;">np</span></span></span><br/><span style="font-size:14px;">&nbsp;</span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">randn</span>(<span class="cm-number" style="font-size:14px;">2</span>, <span class="cm-number" style="font-size:14px;">2</span>, <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;</span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># From numpy</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">np</span>.<span class="cm-property" style="font-size:14px;">array</span>([<span class="cm-number" style="font-size:14px;">1.</span>, <span class="cm-number" style="font-size:14px;">2.</span>, <span class="cm-number" style="font-size:14px;">3.</span>]) <span class="cm-comment" style="font-size:14px;">#Only Tensors of floating point dtype can require gradients</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">from_numpy</span>(<span class="cm-variable" style="font-size:14px;">x</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># Now enable gradient</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span>.<span class="cm-property" style="font-size:14px;">requires_grad_</span>(<span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># _ above makes the change in-place (its a common pytorch thing)</span></span></pre> <p><span style="font-size:14px;"></span></p> <p> <center><br />   <span style="font-size:14px;">创建启用梯度的张量的各种方法的代码</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><strong>注意</strong>：根据PyTorch的设计，梯度只能计算浮点张量，这就是为什么我创建了一个浮点类型的numpy数组，然后将它设置为启用梯度的PyTorch张量。</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Autograd：</strong><strong></strong>这个类是一个计算导数的引擎(更精确地说是雅克比向量积)。它记录了梯度张量上所有操作的一个图，并创建了一个称为动态计算图的非循环图。这个图的叶节点是输入张量，根节点是输出张量。梯度是通过跟踪从根到叶的图形，并使用链式法则将每个梯度相乘来计算的。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">神经网络和反向传播</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">神经网络只不过是经过精心调整(训练)以输出所需结果的复合数学函数。调整或训练是通过一种称为反向传播的出色算法完成的。反向传播用来计算相对于输入权值的损失梯度，以便以后更新权值，最终减少损失。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">在某种程度上，反向传播只是链式法则的一个花哨的名字—— Jeremy Howard</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">创建和训练神经网络包括以下基本步骤：</span></p> <ol class="ol-list list-paddingleft-2"> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">定义体系结构</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">使用输入数据在体系结构上向前传播</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">计算损失</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><strong>反向传播，计算每个权重的梯度</strong><strong></strong></span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">使用学习率更新权重</span></p> </li> </ol> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">损失变化引起的输入权值的微小变化称为该权值的梯度，并使用反向传播计算。然后使用梯度来更新权值，使用学习率来整体减少损失并训练神经网络。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这是以迭代的方式完成的。对于每个迭代，都要计算几个梯度，并为存储这些梯度函数构建一个称为计算图的东西。PyTorch通过构建一个动态计算图(DCG)来实现这一点。此图在每次迭代中从头构建，为梯度计算提供了最大的灵活性。例如，对于前向操作(函数)<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Mul</code></span><span style="font-size:14px;"> ，向后操作函数<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">MulBackward</code>被动态集成到后向图中以计算梯度。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">动态计算图</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">支持梯度的张量(变量)和函数(操作)结合起来创建动态计算图。数据流和应用于数据的操作在运行时定义，从而动态地构造计算图。这个图是由底层的autograd类动态生成的。你不必在启动训练之前对所有可能的路径进行编码——你运行的是你所区分的。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">一个简单的DCG用于两个张量的乘法会是这样的：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/45e34b846476039c94016f89f14506a6.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">带有requires_grad = False的DCG</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">图中的每个点轮廓框是一个变量，紫色矩形框是一个操作。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">每个变量对象都有几个成员，其中一些成员是：</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Data</strong>：它是一个变量持有的数据。<strong>x</strong>持有一个1x1张量，其值等于1.0，而<strong>y</strong>持有2.0。<strong>z</strong>持有两个的乘积，即2.0。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>requires_grad</strong>：这个成员(如果为true)开始跟踪所有的操作历史，并形成一个用于梯度计算的向后图。对于任意张量<strong>a</strong>，可以按如下方式对其进行原地处理：<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">a.requires_grad_(True)</code>。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>grad:</strong> grad保存梯度值。如果<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code> 为False，它将持有一个None值。即使<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code> 为真，它也将持有一个None值，除非从其他节点调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.backward()</code>函数。例如，如果你对<strong>out</strong>关于<strong>x</strong>计算梯度，调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">out.backward()</code>，则<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x.grad</code>的值为<strong>∂out/∂x</strong>。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>grad_fn</strong>：这是用来计算梯度的向后函数。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>is_leaf</strong>：如果：</span></p> <ol class="ol-list list-paddingleft-2"> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它被一些函数显式地初始化，比如<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x = torch.tensor(1.0)</code>或<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x = torch.randn(1, 1)</code>(基本上是本文开头讨论的所有张量初始化方法)。</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它是在张量的操作之后创建的，所有张量都有<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad = False</code>。</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它是通过对某个张量调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.detach()</code>方法创建的。</span></p> </li> </ol> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward()</code>时，只计算<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code>和<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">is_leaf</code>同时为真的节点的梯度。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">当打开 <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad = True</code>时，PyTorch将开始跟踪操作，并在每个步骤中存储梯度函数，如下所示：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/5d458ba5bc4aa41de544540a487b5e44.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">requires_grad = True的DCG</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在PyTorch下生成上图的代码是：</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">Backward()函数</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">Backward函数实际上是通过传递参数(默认情况下是1x1单位张量)来计算梯度的，它通过Backward图一直到每个叶节点，每个叶节点都可以从调用的根张量追溯到叶节点。然后将计算出的梯度存储在每个叶节点的<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.grad</code>中。<em>请记住，在正向传递过程中已经动态生成了后向图。</em><em>backward函数仅使用已生成的图形计算梯度，并将其存储在叶节点中。</em></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">让我们分析以下代码：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">torch</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># Creating the graph</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>(<span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span> = <span class="cm-variable" style="font-size:14px;">x</span> <span class="cm-operator" style="font-size:14px;">**</span> <span class="cm-number" style="font-size:14px;">3</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span>.<span class="cm-property" style="font-size:14px;">backward</span>() <span class="cm-comment" style="font-size:14px;">#Computes the gradient</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-builtin" style="font-size:14px;">print</span>(<span class="cm-variable" style="font-size:14px;">x</span>.<span class="cm-property" style="font-size:14px;">grad</span>.<span class="cm-property" style="font-size:14px;">data</span>) <span class="cm-comment" style="font-size:14px;">#Prints '3' which is dz/dx</span></span></span></pre> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">需要注意的一件重要事情是，当调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code>时，一个张量会自动传递为<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward(torch.tensor(1.0))</code>。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.tensor(1.0)</code>是用来终止链式法则梯度乘法的外部梯度。这个外部梯度作为输入传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">MulBackward</code>函数，以进一步计算<strong>x</strong>的梯度。传递到<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.backward()</code>中的张量的维数必须与正在计算梯度的张量的维数相同。例如，如果梯度支持张量x和y如下：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>([<span class="cm-number" style="font-size:14px;">0.0</span>, <span class="cm-number" style="font-size:14px;">2.0</span>, <span class="cm-number" style="font-size:14px;">8.0</span>], <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">y</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>([<span class="cm-number" style="font-size:14px;">5.0</span> , <span class="cm-number" style="font-size:14px;">1.0</span> , <span class="cm-number" style="font-size:14px;">7.0</span>], <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span> = <span class="cm-variable" style="font-size:14px;">x</span> <span class="cm-operator" style="font-size:14px;">*</span> <span class="cm-variable" style="font-size:14px;">y</span></span></span></pre> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">然后，要计算<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z</code>关于<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x</code>或者<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">y</code>的梯度，需要将一个外部梯度传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code>函数，如下所示：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span>.<span class="cm-property" style="font-size:14px;">backward</span>(<span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">FloatTensor</span>([<span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-number" style="font-size:14px;">1.0</span>])</span></span></pre> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code></span><span style="font-size:14px;"> 会给出 <em>RuntimeError: grad can be implicitly created only for scalar outputs</em><em></em></span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">反向函数传递的张量就像梯度加权输出的权值。从数学上讲，这是一个向量乘以非标量张量的雅可比矩阵(本文将进一步讨论)，因此它几乎总是一个维度的单位张量，与 <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward</code>张量相同，除非需要计算加权输出。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">tldr ：向后图是由autograd类在向前传递过程中自动动态创建的。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Backward()</code>只是通过将其参数传递给已经生成的反向图来计算梯度。</span></p> </blockquote> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">数学—雅克比矩阵和向量</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">从数学上讲，autograd类只是一个雅可比向量积计算引擎。雅可比矩阵是一个非常简单的单词，它表示两个向量所有可能的偏导数。它是一个向量相对于另一个向量的梯度。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">注意：在这个过程中，PyTorch从不显式地构造整个雅可比矩阵。直接计算JVP (Jacobian vector product)通常更简单、更有效。</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">如果一个向量<strong>X = [x1, x2，…xn]</strong>通过<strong>f(X) = [f1, f2，…fn]</strong>来计算其他向量，则雅可比矩阵(<strong>J</strong>)包含以下所有偏导组合：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/91836c1d6fbfe79529bef05b61bf4e0c.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">雅克比矩阵</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">上面的矩阵表示<strong>f(X)</strong>相对于<strong>X</strong>的梯度。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">假设一个启用PyTorch梯度的张量<strong>X</strong>：</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>X = [x1,x2,…,xn]</strong>(假设这是某个机器学习模型的权值)</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>X</strong>经过一些运算形成一个向量<strong>Y</strong><strong></strong></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Y = f(X) = [y1, y2，…,ym]</strong><strong></strong></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">然后使用<strong>Y</strong>计算标量损失<strong>l</strong>。假设向量<strong>v</strong>恰好是标量损失<strong>l</strong>关于向量<strong>Y</strong>的梯度，如下：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" style="width:258px;" src="http://img.555519.xyz/uploads/20230108/bbaa29ffeba3fecebb34db31d8610d0e.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">向量v称为<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">grad_tensor</code>，并作为参数传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward()</code> 函数。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">为了得到损失的梯度<strong>l</strong>关于权重<strong>X</strong>的梯度，雅可比矩阵<strong>J</strong>是向量乘以向量<strong>v</strong><strong></strong></span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/09d7044c0878c4c9583d9905530b29e7.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这种计算雅可比矩阵并将其与向量<strong>v</strong>相乘的方法使PyTorch能够轻松地为非标量输出提供外部梯度。</span></p> <p> <img decoding="async" src="http://img.555519.xyz/uploads/20230108/7ea178cfe90f586a0961b9249544c533.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法">—<br />  END—</p> <p style="min-height:1em;letter-spacing:.544px;width:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;letter-spacing:.544px;">英文原文：https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95</span></p> </div></div> 			                <div class="clearfix"></div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/news/article-23487.htm">宠物医院办证流程（宠物医院办证流程图片）</a></p>
                                        <p>下一个：<a href="/news/article-23938.htm">宠物粮食加工厂设备生产厂家电话号码查询（宠物粮食加工厂设备生产厂家电话号码查询）</a></p>
                                    </div>
                                </div>
                <div class="col-md-3">
                    <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/news/article-23938.htm" title="宠物粮食加工厂设备生产厂家电话号码查询（宠物粮食加工厂设备生产厂家电话号码查询）">宠物粮食加工厂设备生产厂家电话号码查询（宠物粮食加工厂设备生产厂家电话号码查询）</a></li>
                        <li class="py-2"><a href="/news/article-18911.htm" title="领养宠物需要注意的事项有哪些（领养宠物需要收费吗）">领养宠物需要注意的事项有哪些（领养宠物需要收费吗）</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-11-20-hysteria-node-github.htm" title="「11月20日」最高速度18M/S，2024年Hysteria每天更新免费机场订阅节点链接">「11月20日」最高速度18M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-8-27-free-subscribe-node.htm" title="「8月27日」最高速度18.5M/S，2024年Hysteria每天更新免费机场订阅节点链接">「8月27日」最高速度18.5M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/news/article-21633.htm" title="十大品牌兽药厂家 十大品牌兽药厂家是哪些">十大品牌兽药厂家 十大品牌兽药厂家是哪些</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-9-1-hysteria-github.htm" title="「9月1日」最高速度18M/S，2024年Hysteria每天更新免费机场订阅节点链接">「9月1日」最高速度18M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-10-13-free-node-subscribe-links.htm" title="「10月13日」最高速度22.9M/S，2024年Hysteria每天更新免费机场订阅节点链接">「10月13日」最高速度22.9M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-10-21-hysteria-github.htm" title="「10月21日」最高速度20.8M/S，2024年Hysteria每天更新免费机场订阅节点链接">「10月21日」最高速度20.8M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-10-31-node-share-links.htm" title="「10月31日」最高速度19.2M/S，2024年Hysteria每天更新免费机场订阅节点链接">「10月31日」最高速度19.2M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-10-2-hysteria-node-github.htm" title="「10月2日」最高速度22.8M/S，2024年Hysteria每天更新免费机场订阅节点链接">「10月2日」最高速度22.8M/S，2024年Hysteria每天更新免费机场订阅节点链接</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">33</span> <a href="/date/2024-12/" title="2024-12 归档">2024-12</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">34</span> <a href="/date/2024-11/" title="2024-11 归档">2024-11</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">31</span> <a href="/date/2024-10/" title="2024-10 归档">2024-10</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">30</span> <a href="/date/2024-09/" title="2024-09 归档">2024-09</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">18</span> <a href="/date/2024-08/" title="2024-08 归档">2024-08</a></h4>
            </li>
                    </ul>
    </div>
</div>

                </div>
            </div>
        </div>
    </section>
    <!--================About Area End =================-->
        <!-- ================ start footer Area ================= -->
    <footer class="footer-area">
        <div class="container">
            <div class="footer-bottom row align-items-center text-center text-lg-left no-gutters">
                <p class="footer-text m-0 col-lg-8 col-md-12">
                    HysteriaWindows免费节点官网 版权所有 Powered by WordPress
                </p>
                <div class="col-lg-4 col-md-12 text-center text-lg-right footer-social">
                    <a href="#"><i class="ti-facebook"></i></a>
                    <a href="#"><i class="ti-twitter-alt"></i></a>
                    <a href="#"><i class="ti-dribbble"></i></a>
                    <a href="#"><i class="ti-linkedin"></i></a>
                </div>
            </div>
        </div>
    </footer>
    <!-- ================ End footer Area ================= -->
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="/assets/website/js/frontend/hysteriawindows/jquery-3.5.1.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/popper.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/bootstrap.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/owl-carousel/owl.carousel.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/jquery.ajaxchimp.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/waypoints.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/mail-script.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/contact.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/jquery.form.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/jquery.validate.min.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/mail-script.js"></script>
    <script src="/assets/website/js/frontend/hysteriawindows/theme.js"></script>
    <script src="https://www.freeclashnode.com/assets/js/frontend/invite-url.js"></script><script src="/assets/website/js/frontend/G.js"></script>
</body>

</html>